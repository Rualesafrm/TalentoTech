{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Actividad práctica: Como actividad práctica, se propone tokenizar textos utilizando herramientas como NLTK (Natural Language Toolkit) u otras disponibles. Esto permitirá aplicar los conceptos aprendidos sobre tokenización en un contexto práctico y familiarizarse con el uso de herramientas de procesamiento del lenguaje natural.\n",
        "Se explicará cómo tokenizar textos utilizando NLTK (Natural Language Toolkit), una biblioteca de procesamiento del lenguaje natural en Python.\n",
        "\n",
        "Instalación de NLTK\n",
        "Primero, es necesario instalar NLTK si aún no está presente. Esto se puede lograr utilizando pip, el gestor de paquetes de Python:\n",
        "En el terminal de preferencia (Visual studio code, Pycharm etc).\n"
      ],
      "metadata": {
        "id": "zszCLHSOh3lz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install nltk\n"
      ],
      "metadata": {
        "id": "v5jy9Wzah4iL"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importación de NLTK y Descarga de Recursos\n",
        "Una vez instalado NLTK, se debe importar en el script Python. Además, es necesario descargar recursos adicionales, como modelos y corpus, que NLTK utiliza para realizar ciertas tareas, como la tokenización. Esto se puede hacer ejecutando el siguiente código en un terminal de Python:\n"
      ],
      "metadata": {
        "id": "GgdddFFvh9zr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T1t-9UPh_fJ",
        "outputId": "abe66bef-bf49-43dc-beae-9c4717aea0cd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenización de Textos\n"
      ],
      "metadata": {
        "id": "GsnA4me2iA4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "texto = \"NLTK es una biblioteca de procesamiento del lenguaje natural. ¡Es genial!\"\n",
        "\n",
        "tokens = word_tokenize(texto)\n",
        "\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Qad4UEhiBPf",
        "outputId": "1042c8b6-4c8b-48f8-9854-9c171bbc67c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLTK', 'es', 'una', 'biblioteca', 'de', 'procesamiento', 'del', 'lenguaje', 'natural', '.', '¡Es', 'genial', '!']\n"
          ]
        }
      ]
    }
  ]
}