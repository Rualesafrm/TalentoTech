{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "El taller de análisis de textos se estructura en dos partes. En la primera hora, se llevará a cabo una sesión práctica utilizando Python como herramienta principal. Se aprenderá a realizar tareas de procesamiento de lenguaje natural, como tokenización y lematización de texto, así como el análisis de la frecuencia de palabras. Se utilizarán bibliotecas populares como NLTK y Pandas para implementar estos procesos y se realizará una visualización básica de datos utilizando Matplotlib. En la segunda hora, se abordarán aspectos teóricos del procesamiento de lenguaje natural, incluyendo conceptos avanzados como modelos de lenguaje, aprendizaje profundo en NLP y consideraciones éticas en el análisis de textos."
      ],
      "metadata": {
        "id": "Q8xvguO-ib5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalación de librerías necesarias\n",
        "!pip install nltk pandas matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLwa-4dsidwV",
        "outputId": "e7a2c91a-0a2b-4e9a-fe5f-96a8ef07b48c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenización de Texto\n",
        "Adicione, lo necesario para la tokenización, deberá añadir y argumento de la variable text.\n"
      ],
      "metadata": {
        "id": "YPt56fZFiiX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = #Adjunte el texto de su agrado\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens:\", tokens)\n"
      ],
      "metadata": {
        "id": "5obnfl76ijT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lematización de Palabras\n",
        "Complete el siguiente script (Nota: Este contiene partes sin rellenar)\n"
      ],
      "metadata": {
        "id": "PbTXXSbDikkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_words = #Deberá completar esta parte\n",
        "print(\"Lematizados:\", lemmatized_words)\n"
      ],
      "metadata": {
        "id": "OBlmCm25imIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análisis de Frecuencia de Palabras"
      ],
      "metadata": {
        "id": "GSWSC5EeindP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "word_freq = pd.Series(lemmatized_words).value_counts()\n",
        "print(\"Frecuencia de palabras:\\n\", word_freq)\n",
        "\n"
      ],
      "metadata": {
        "id": "3ZTmq4VGipTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "h8xZQNMiirrz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}